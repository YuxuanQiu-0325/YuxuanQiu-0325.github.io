<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yuxuanqiu-0325.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Blog">
<meta property="og:url" content="https://yuxuanqiu-0325.github.io/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Yuxuan Qiu">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://yuxuanqiu-0325.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://yuxuanqiu-0325.github.io/posts/unified-diffusion/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yuxuan Qiu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/posts/unified-diffusion/" class="post-title-link" itemprop="url">A Unified Dynamical Perspective on Generative Modeling: From Stochastic Diffusion to Deterministic Flows</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2025-07-31 14:00:00" itemprop="dateCreated datePublished" datetime="2025-07-31T14:00:00+09:00">2025-07-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-16 23:27:45" itemprop="dateModified" datetime="2025-08-16T23:27:45+09:00">2025-08-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 class="no-number" style="text-align:center;">Abstract</h1>
This blog aims to provide a unified mathematical and physical perspective on two leading deep generative modeling paradigms: Score-Based Diffusion Models and Flow Matching. We begin with the fundamental concept of a one-dimensional random walk and systematically derive its continuous limit, Brownian motion. This leads to the introduction of core mathematical tools that describe its dynamics: Stochastic Differential Equations (SDEs), the It√¥ Integral, and the Fokker-Planck Equation. Building on this foundation, we conduct an in-depth analysis of the diffusion model framework, clarifying how it connects data and noise by defining a forward noising SDE and learning a reverse denoising SDE. The primary contribution of this paper is the establishment of a unified mathematical and physical framework to interpret generative modeling. By describing the generative process through the language of stochastic differential equations (SDEs) and ordinary differential equations (ODEs), it connects the dynamics of stochastic diffusion with those of deterministic flows.  Furthermore, this blog explores related critical techniques, such as the Probability Flow ODE for accelerated sampling and Optimal Transport Coupling for reducing training variance. Through a unified perspective on dynamics and probability theory, this blog seeks to provide a clear and rigorous theoretical foundation for understanding and comparing these two powerful generative models.

<h1 id="Foundations-of-Stochastic-Dynamics"><a href="#Foundations-of-Stochastic-Dynamics" class="headerlink" title="Foundations of Stochastic Dynamics"></a>Foundations of Stochastic Dynamics</h1><h2 id="Discrete-Random-Walk"><a href="#Discrete-Random-Walk" class="headerlink" title="Discrete Random Walk"></a>Discrete Random Walk</h2><p>We consider a one-dimensional discrete random walk model: a particle moves a fixed step length $\Delta x$ to the right with a probability of $0.5$ or to the left by the same step length with a probability of $0.5$, within each time step $\Delta t$. Let the random variable $X_i$ denote the displacement in the $i$-th step.</p>
<h3 id="Single-Step-Statistical-Properties"><a href="#Single-Step-Statistical-Properties" class="headerlink" title="Single-Step Statistical Properties"></a>Single-Step Statistical Properties</h3><p>The core statistical properties for any single-step displacement $X_i$ are as follows:</p>
<ul>
<li><p><strong>Expectation</strong>: The mean displacement for each step is $0$, which indicates that the random motion is unbiased.</p>
<p>  $$<br>  \mathbb{E}[X_i] &#x3D; (+\Delta x) \times 0.5 + (-\Delta x) \times 0.5 &#x3D; 0<br>  $$</p>
</li>
<li><p><strong>Variance</strong>: The variance reflects the uncertainty or magnitude of fluctuation for each step‚Äôs displacement.</p>
<p>  $$<br>  \mathrm{Var}(X_i) &#x3D; \mathbb{E}[X_i^2] - (\mathbb{E}[X_i])^2 &#x3D; (\Delta x)^2 \times 0.5 + (-\Delta x)^2 \times 0.5 - 0^2 &#x3D; (\Delta x)^2<br>  $$</p>
</li>
</ul>
<h3 id="Multi-Step-Statistical-Properties"><a href="#Multi-Step-Statistical-Properties" class="headerlink" title="Multi-Step Statistical Properties"></a>Multi-Step Statistical Properties</h3><p>After $n$ steps, the total displacement of the particle, $S_n$, is the sum of the individual independent displacements, i.e., $S_n &#x3D; \sum_{i&#x3D;1}^n X_i$.</p>
<ul>
<li><p><strong>Expectation</strong>: Regardless of the number of steps taken, the expected position (i.e., the average position) of the particle remains at the origin.<br>  $$<br>  \mathbb{E}[S_n] &#x3D; \sum_{i&#x3D;1}^n \mathbb{E}[X_i] &#x3D; 0<br>  $$</p>
</li>
<li><p><strong>Variance</strong>: The variance of the total displacement is proportional to the number of steps, $n$. This implies that the more steps are taken, the larger the potential range of the particle‚Äôs movement becomes.<br>  $$<br>  \mathrm{Var}(S_n) &#x3D; \sum_{i&#x3D;1}^n \mathrm{Var}(X_i) &#x3D; n (\Delta x)^2<br>  $$</p>
</li>
</ul>
<h2 id="Transition-to-Continuous-Brownian-Motion"><a href="#Transition-to-Continuous-Brownian-Motion" class="headerlink" title="Transition to Continuous Brownian Motion}"></a>Transition to Continuous Brownian Motion}</h2><p>To derive the continuous-time limit from the discrete random walk, we construct a stochastic process $S(t)$ and examine its convergence behavior as the time step $\Delta t \to 0$ and the space step $\Delta x \to 0$. Let the total time $t &#x3D; n \cdot \Delta t$ be held as a finite constant, which implies that as $\Delta t \to 0$, the number of steps $n \to \infty$. On this timescale, the variance of the total displacement $S_n$ can be rewritten as:<br>$$<br>\mathrm{Var}(S_n) &#x3D; n(\Delta x)^2 &#x3D; \frac{t}{\Delta t}(\Delta x)^2 &#x3D; t \frac{(\Delta x)^2}{\Delta t}<br>$$<br>For the stochastic process to converge to a non-trivial limit‚Äîthat is, a process that neither collapses to zero nor diverges to infinity‚Äîthe variance of the total displacement must converge to a non-zero, finite value. This requires the ratio $\frac{(\Delta x)^2}{\Delta t}$ to be a constant in the limit as $\Delta t \to 0$. We accordingly define this constant as the square of the diffusion coefficient, denoted as $\sigma^2$:<br>\begin{equation*}<br>\lim_{\Delta t \to 0} \frac{(\Delta x)^2}{\Delta t} \equiv \sigma^2 \implies \Delta x \approx \sigma\sqrt{\Delta t}<br>\end{equation*}</p>
<p>Here, $\sigma$ is known as the <strong>diffusion coefficient</strong>. It quantifies the growth rate of the particle‚Äôs spatial range (i.e., its uncertainty) per unit of time. Based on this scaling relationship, we can determine the key statistical properties of the continuous process:<br>\begin{equation}<br>\mathbb{E}[S(t)] &#x3D; \lim_{n \to \infty} \mathbb{E}[S_n] &#x3D; 0,\quad\mathrm{Var}(S(t)) &#x3D; \sigma^2 t<br>\label{eq:1}<br>\end{equation}</p>
<p>According to the functional <strong>Central Limit Theorem</strong>, as $n \to \infty$, the discrete random walk process $S_n$ converges in distribution to a continuous stochastic process known as the Wiener Process, or standard Brownian motion. Therefore, at any given time $t$, the probability distribution of the particle‚Äôs position is a normal distribution with a mean of $0$ and a variance of $\sigma^2 t$:<br>\begin{equation}<br>S(t) \sim \mathcal{N}(0, \sigma^2 t)<br>\end{equation}</p>
<h2 id="Derivation-of-the-Macroscopic-Diffusion-Equation"><a href="#Derivation-of-the-Macroscopic-Diffusion-Equation" class="headerlink" title="Derivation of the Macroscopic Diffusion Equation"></a>Derivation of the Macroscopic Diffusion Equation</h2><p>Previously, we described the random behavior of a single particle over long timescales, where its position probability distribution $S_n$ converges to a normal distribution $\mathcal{N}(0, \sigma^2 t)$. We now shift from the microscopic, single-particle random perspective to a macroscopic, deterministic view of a particle ensemble, aiming to derive the partial differential equation (PDE) that describes the spatiotemporal evolution of the particle number density $\rho(x, t)$. </p>
<p>We assume the evolution of the particle cloud is a Markovian process, whose temporal evolution can be described by the Chapman-Kolmogorov equation. At time $t + \Delta t$, the particle density at position $x$ is the sum of contributions from all particles that were at other positions $x-z$ at time $t$ and arrived at $x$ after a single displacement step $z$:<br>\begin{equation}<br>\rho(x, t + \Delta t) &#x3D; \int_{-\infty}^{\infty} \rho(x - z, t), \phi(z), \mathrm{d}z<br>\label{eq:chapman_kolmogorov}<br>\end{equation}<br>where $\phi(z)$ is the stationary probability density function (PDF) of a single-step jump displacement $z$, which does not vary with time or space.</p>
<p>To derive a differential equation from this integral equation, we perform a Taylor series expansion on both sides in the limit as $\Delta t \to 0$.<br>The left side of the equation, $\rho(x, t + \Delta t)$, is expanded with respect to time $t$, keeping terms up to the first order:<br>\begin{equation}<br>\rho(x, t + \Delta t) \approx \rho(x, t) + \frac{\partial \rho(x, t)}{\partial t} \Delta t<br>\label{eq:taylor_time}<br>\end{equation}<br>The term $\rho(x - z, t)$ inside the integral on the right side is expanded with respect to the spatial displacement $z$, keeping terms up to the second order due to the infinitesimal nature of $z$:<br>\begin{equation}<br>\rho(x - z, t) \approx \rho(x, t) - z \frac{\partial \rho(x, t)}{\partial x} + \frac{z^2}{2} \frac{\partial^2 \rho(x, t)}{\partial x^2}<br>\label{eq:taylor_space}<br>\end{equation}</p>
<p>Substituting Eq.<del>\eqref{eq:taylor_space} into the right side of Eq.</del>\eqref{eq:chapman_kolmogorov}, we obtain:<br>$$<br>\int_{-\infty}^{\infty} \left[ \rho(x, t) - z \frac{\partial \rho}{\partial x} + \frac{z^2}{2} \frac{\partial^2 \rho}{\partial x^2} \right] \phi(z), \mathrm{d}z<br>&#x3D; \rho \int \phi(z)\mathrm{d}z - \frac{\partial \rho}{\partial x} \int z\phi(z)\mathrm{d}z + \frac{1}{2}\frac{\partial^2 \rho}{\partial x^2} \int z^2\phi(z)\mathrm{d}z<br>$$<br>We utilize the statistical properties of $\phi(z)$:</p>
<ul>
<li><strong>Probability normalization</strong>: $\int_{-\infty}^{\infty} \phi(z) \mathrm{d}z &#x3D; 1$</li>
<li><strong>Zero mean</strong> (assuming symmetric jumps): $\mathbb{E}[z] &#x3D; \int_{-\infty}^{\infty} z \phi(z) \mathrm{d}z &#x3D; 0$</li>
<li><strong>Finite second moment</strong> (variance): $\mathbb{E}[z^2] &#x3D; \int_{-\infty}^{\infty} z^2 \phi(z) \mathrm{d}z &#x3D; \sigma_z^2$</li>
</ul>
<p>Thus, the right side of the  Eq.\eqref{eq:chapman_kolmogorov} can be approximated as $\rho(x, t) + \frac{1}{2} \frac{\partial^2 \rho}{\partial x^2} \mathbb{E}[z^2]$. Combining the time expansion from Eq.~\eqref{eq:taylor_time} with the result above, we have:<br>$$<br>\rho(x, t) + \frac{\partial \rho}{\partial t} \Delta t \approx \rho(x, t) + \frac{1}{2} \frac{\partial^2 \rho}{\partial x^2} \mathbb{E}[z^2]<br>$$<br>Canceling $\rho(x, t)$ and dividing by $\Delta t$, we arrive at the difference quotient form:<br>$$<br>\frac{\partial \rho(x, t)}{\partial t} \approx \frac{\mathbb{E}[z^2]}{2\Delta t} \frac{\partial^2 \rho(x, t)}{\partial x^2}<br>$$<br>In the continuous limit as $\Delta t \to 0$, we define the macroscopic <strong>Diffusion Coefficient</strong> $D$:<br>\begin{equation}<br>D \equiv \lim_{\Delta t \to 0} \frac{\mathbb{E}[z^2]}{2\Delta t}<br>\label{eq:5}<br>\end{equation}<br>Finally, we obtain the famous partial differential equation describing the evolution of particle density‚Äîthe <strong>Diffusion Equation</strong>, also known as Fick‚Äôs second law:<br>\begin{equation}<br>\frac{\partial \rho(x, t)}{\partial t} &#x3D; D \frac{\partial^2 \rho(x, t)}{\partial x^2}<br>\end{equation}<br>This is a deterministic equation that describes the average macroscopic effect of the collective behavior of a large number of independent random-walking particles. Therefore, Eulerian perspective that describes the particle cloud‚Äôs density via the diffusion equation, and the microscopic, Lagrangian perspective that tracks a single particle‚Äôs trajectory are unified descriptions of the same underlying process:</p>
<p>For a single particle, the variance of a single-step jump is $\sigma^2 \Delta t$ from Eq.\ref{eq:1}. Substituting this into the definition of the diffusion coefficient from Eq.\ref{eq:5}:<br> $$<br> D &#x3D; \frac{(\Delta x)^2}{2\Delta t} &#x3D; \frac{\sigma^2 \Delta t}{2\Delta t} &#x3D; \frac{\sigma^2}{2}<br> $$</p>
<p>If all particles are initially concentrated at the origin ($\rho(x, 0) &#x3D; \delta(x)$), the solution to the diffusion equation at time $t$ is<br> $$<br>\rho(x, t) &#x3D; \frac{1}{\sqrt{4\pi D t}} \exp\left(-\frac{x^2}{4Dt}\right)<br>&#x3D; \frac{1}{\sqrt{2\pi \sigma^2 t}} \exp\left(-\frac{x^2}{2\sigma^2 t}\right)<br>$$</p>
<p>This is precisely a normal distribution $\mathcal{N}(0,, \sigma^2 t)$ with a mean of $0$ and a variance of $\sigma^2 t$, which is in perfect agreement with the limiting distribution we derived from the single-particle process. Therefore, the smooth diffusion of particle density on a macroscopic scale is, in essence, the statistical manifestation of the independent, random motion of a large number of particles.</p>
<h2 id="Stochastic-Differential-Equations-and-the-Fokker-Planck-Equation"><a href="#Stochastic-Differential-Equations-and-the-Fokker-Planck-Equation" class="headerlink" title="Stochastic Differential Equations and the Fokker-Planck Equation"></a>Stochastic Differential Equations and the Fokker-Planck Equation</h2><p>The preceding discussion has focused on the simplest form of Brownian motion, characterized by the absence of external forces and a constant diffusion coefficient. In a more general framework, the trajectory of a single particle simultaneously influenced by deterministic forces and random fluctuations can be modeled by a <strong>Stochastic Differential Equation (SDE)</strong>. Its It√¥ form is typically written as:<br>\begin{equation} \label{eq:sde_general_en}<br>\mathrm{d}X_t &#x3D; \mu(X_t, t)\mathrm{d}t + \sigma(X_t, t)\mathrm{d}W_t<br>\end{equation}<br>The terms in this equation represent different physical effects:</p>
<ul>
<li>The <strong>drift term</strong>, $\mu(X_t, t)\mathrm{d}t$, describes the deterministic part of the particle‚Äôs motion. It represents the average infinitesimal displacement caused by a systematic force field.</li>
<li>The <strong>diffusion term</strong>, $\sigma(X_t, t)\mathrm{d}W_t$, models the random component arising from stochastic phenomena (such as collisions with surrounding molecules). The intensity of this random motion is controlled by the diffusion coefficient $\sigma(X_t, t)$, while $\mathrm{d}W_t$ is the infinitesimal increment of the Wiener process.</li>
</ul>
<p>The SDE provides a Lagrangian description of a single particle‚Äôs trajectory, while the corresponding Eulerian description, which describes the evolution of the probability density function $\rho(x, t)$ for an ensemble of such particles, is given by the <strong>Fokker-Planck Equation</strong>:<br>\begin{equation} \label{eq:fpe_general_en}<br>\frac{\partial \rho(x, t)}{\partial t} &#x3D; -\frac{\partial}{\partial x} \left[ \mu(x, t)\rho(x, t) \right] + \frac{\partial^2}{\partial x^2} \left[ D(x, t)\rho(x, t) \right]<br>\end{equation}<br>Here, the diffusion coefficient $D(x, t)$ is related to the SDE‚Äôs diffusion term by the relation $D(x, t) &#x3D; \frac{1}{2}\sigma(x, t)^2$.</p>
<p>In the special case of standard Brownian motion, the system is not subject to external forces ($\mu(x, t) &#x3D; 0$) and experiences random fluctuations of constant intensity ($\sigma(x, t) &#x3D; \sigma$, where $\sigma$ is a constant). In this case, the SDE from Eq.<del>\eqref{eq:sde_general_en} simplifies to:<br>$$<br>\mathrm{d}X_t &#x3D; \sigma \mathrm{d}W_t<br>$$<br>Correspondingly, the Fokker-Planck Equation from Eq.</del>\eqref{eq:fpe_general_en} degenerates into the standard diffusion equation we derived earlier:<br>$$<br>\frac{\partial \rho}{\partial t} &#x3D; D \frac{\partial^2 \rho}{\partial x^2}<br>$$<br>where $D &#x3D; \sigma^2 &#x2F; 2$.</p>
<p>These two perspectives‚Äîthe microscopic stochastic dynamics of a single particle (SDE) and the macroscopic deterministic evolution of the probability density for a particle ensemble (Fokker-Planck) are mathematically equivalent descriptions of the same underlying physical process. The smooth diffusion phenomenon observed on a macroscopic scale is the statistical manifestation of countless independent random events occurring on a microscopic scale.</p>
<h2 id="Limiting-Case-Degeneration-from-SDE-to-ODE"><a href="#Limiting-Case-Degeneration-from-SDE-to-ODE" class="headerlink" title="Limiting Case: Degeneration from SDE to ODE"></a>Limiting Case: Degeneration from SDE to ODE</h2><p>The relationship between a Stochastic Differential Equation (SDE) and an Ordinary Differential Equation (ODE) can be understood by examining the limiting case where the stochastic term vanishes. The general form of an SDE is:<br>$$<br>\mathrm{d}X_t &#x3D; \mu(X_t, t)\mathrm{d}t + \sigma(X_t, t)\mathrm{d}W_t<br>$$<br>When the intensity of the stochastic term approaches zero, i.e., $\sigma(X_t, t) \to 0$, the random fluctuations are suppressed, and the SDE degenerates into a purely deterministic ODE:<br>\begin{equation}<br>\mathrm{d}x_t &#x3D; \mu(x_t, t)\mathrm{d}t \quad \implies \quad \frac{\mathrm{d}x}{\mathrm{d}t} &#x3D; \mu(x, t)<br>\end{equation}<br>In this limit, the particle‚Äôs trajectory is uniquely determined by its initial conditions and the velocity field $\mu(x, t)$, containing no randomness.</p>
<p>This transition is also directly reflected in the corresponding evolution of the probability density. As $\sigma(x, t) \to 0$, the diffusion coefficient $D(x,t) &#x3D; \sigma^2(x,t)&#x2F;2$ also approaches zero. Consequently, the diffusion term in the Fokker-Planck equation vanishes, and the equation simplifies to the <strong>Liouville equation</strong>, a form of the continuity equation:<br>\begin{equation}<br>\frac{\partial \rho(x, t)}{\partial t} &#x3D; -\frac{\partial}{\partial x}[\mu(x, t)\rho(x, t)]<br>\label{eq:ode_FPE}<br>\end{equation}<br>This equation describes a process where the probability density is transported purely by the deterministic drift field $\mu(x, t)$. It signifies that the total probability is conserved, and the evolution of the density arises solely from advection by the underlying deterministic flow, without any additional diffusion or broadening.</p>
<h1 id="Diffusion-Models"><a href="#Diffusion-Models" class="headerlink" title="Diffusion Models"></a>Diffusion Models</h1><p>The core objective of a generative model is to learn an empirical data distribution $p_{\text{data}}(x)$. This distribution is typically high-dimensional and multimodal, and its probability density function is analytically intractable, known only through a finite dataset  ${ x_i }_{i&#x3D;1}^N$. </p>
<p>However, the Manifold Hypothesis posits that such data points $x$ are concentrated on a low-dimensional manifold $\mathcal{M}$ embedded within the high-dimensional ambient space. This assumption reframes the generative task from directly estimating the intractable density $p_{\text{data}}$ to learning a parameterized transformation $f_\theta$. This function is designed to map a simple, easy-to-sample prior distribution $p_{\text{init}}$ (e.g., a standard normal distribution) onto the complex data distribution residing on the manifold. The fundamental task can thus be summarized as learning a mapping such that:<br>$$<br>p_{\text{init}} \xrightarrow{f_\theta} p_{\text{data}}<br>$$</p>
<h2 id="Ito‚Äôs-Lemma-and-Euler-Maruyama-Discretization"><a href="#Ito‚Äôs-Lemma-and-Euler-Maruyama-Discretization" class="headerlink" title="It√¥‚Äôs Lemma and Euler-Maruyama Discretization"></a>It√¥‚Äôs Lemma and Euler-Maruyama Discretization</h2><h3 id="Ito‚Äôs-Lemma-and-the-Ito-Integral"><a href="#Ito‚Äôs-Lemma-and-the-Ito-Integral" class="headerlink" title="It√¥‚Äôs Lemma and the It√¥ Integral"></a>It√¥‚Äôs Lemma and the It√¥ Integral</h3><p><strong>It√¥‚Äôs Lemma</strong> is a cornerstone of stochastic analysis, providing a version of the chain rule for the calculus of stochastic processes. Consider a random variable $X_t$ described by the following It√¥ process:<br>\begin{equation}<br>\mathrm{d}X_t &#x3D; \mu(X_t, t)\mathrm{d}t + \sigma(X_t, t)\mathrm{d}W_t \label{eq:sde_ito_revised}<br>\end{equation}<br>Let $f(t, x)$ be a twice continuously differentiable scalar function of time $t$ and state $x$. It√¥‚Äôs Lemma gives the total differential of $f(t, X_t)$ as:<br>\begin{equation}<br>\mathrm{d}f(t, X_t) &#x3D; \left( \frac{\partial f}{\partial t} + \mu(X_t, t)\frac{\partial f}{\partial x} + \frac{1}{2}\sigma(X_t, t)^2 \frac{\partial^2 f}{\partial x^2} \right)\mathrm{d}t + \sigma(X_t, t)\frac{\partial f}{\partial x}\mathrm{d}W_t<br>\label{eq:ito_lemma_full_revised}<br>\end{equation}<br>Compared to the chain rule of classical calculus, It√¥‚Äôs Lemma includes an additional second-derivative term. This term arises from the non-zero quadratic variation of the Wiener process ($(\mathrm{d}W_t)^2 &#x3D; \mathrm{d}t$) and is crucial for accurately describing the evolution of stochastic processes.</p>
<p>The solution to the SDE in Eq.~\eqref{eq:sde_ito_revised} requires integrating both sides. The integral of the drift term, $\mu(X_t, t)\mathrm{d}t$, is a standard Riemann integral. However, due to the nowhere-differentiable nature of the Wiener process, the integral of the diffusion term, $\sigma(X_t, t)\mathrm{d}W_t$, must be defined using a special formulation, namely the <strong>It√¥ Integral</strong> (for a derivation, see Appendix B). The complete integral form of the SDE is written as:<br>\begin{equation}<br>X_T &#x3D; X_0 + \int_0^T \mu(X_t, t)\mathrm{d}t + \int_0^T \sigma(X_t, t)\mathrm{d}W_t<br>\label{eq:sde_integral_form}<br>\end{equation}</p>
<h3 id="Discretizing-the-It-o-Integral-The-Euler-Maruyama-Method"><a href="#Discretizing-the-It-o-Integral-The-Euler-Maruyama-Method" class="headerlink" title="Discretizing the It^o Integral: The Euler-Maruyama Method"></a>Discretizing the It^o Integral: The Euler-Maruyama Method</h3><p>Analytically solving the integral form of an SDE, Eq.~\eqref{eq:sde_integral_form}, is often very difficult. Therefore, we resort to numerical methods to approximate its solution, the most fundamental of which is the Euler-Maruyama Method. The core idea of this method is to discretize the continuous integration process into a series of small, computable steps.</p>
<p>We discretize the time axis into points $t_i &#x3D; i \cdot h$ with a step size of $h$. Within any given time step $[t_i, t_{i+1}]$, we approximate the integrals from Eq.~\eqref{eq:sde_integral_form} as follows:</p>
<ul>
<li><strong>Drift Term Integral Approximation</strong>: $\int_{t_i}^{t_{i+1}} \mu(X_t, t)\mathrm{d}t \approx \mu(X_i, t_i)h$</li>
<li><strong>Diffusion Term Integral Approximation</strong>: $\int_{t_i}^{t_{i+1}} \sigma(X_t, t)\mathrm{d}W_t \approx \sigma(X_i, t_i)(W_{t_{i+1}} - W_{t_i})$</li>
</ul>
<p>According to the properties of the Wiener process, the increment $\Delta W_i &#x3D; W_{t_{i+1}} - W_{t_i}$ is a random variable drawn from a normal distribution $\mathcal{N}(0, h)$. We can generate it as $\sqrt{h} \cdot \varepsilon_i$, where $\varepsilon_i \sim \mathcal{N}(0, \mathbf{I})$ is a standard normal random variable.</p>
<p>Combining these approximations, we arrive at the iterative update rule for the Euler-Maruyama method:<br>\begin{equation}<br>X_{i+1} &#x3D; X_i + \mu(X_i, t_i)h + \sigma(X_i, t_i)\sqrt{h} \cdot \varepsilon_i<br>\label{eq:euler_maruyama_revised}<br>\end{equation}</p>
<p>In the generative process of a diffusion model, the diffusion coefficient $\sigma(t)$ is typically a predefined schedule. The core modeling task is to learn a parameterized drift function $\mu_\theta(x, t)$ that, during the reverse-time process, can accurately guide a simple noise distribution back to the target data distribution. Once an accurate <strong>$\mu_\theta(x, t)$</strong> is obtained, one can generate data samples $x_T$ from random noise $x_0 \sim \mathcal{N}(0, \mathbf{I})$ by simulating this discretized SDE process.</p>
<p><img src="/pic/1.png" alt="ËøôÊòØÂõæÁâáËØ¥Êòé"></p>
<h2 id="How-to-Learn-mu-theta-x-t"><a href="#How-to-Learn-mu-theta-x-t" class="headerlink" title="How to Learn $\mu_{\theta}(x,t)$?"></a>How to Learn $\mu_{\theta}(x,t)$?</h2><h3 id="From-Simple-to-Complex-or-Complex-to-Simple"><a href="#From-Simple-to-Complex-or-Complex-to-Simple" class="headerlink" title="From Simple to Complex, or Complex to Simple?"></a>From Simple to Complex, or Complex to Simple?</h3><p>The core challenge for generative models is that directly modeling the complex data distribution $p_{\text{data}}$ from a simple distribution is analytically intractable. Diffusion models propose an indirect modeling strategy: first, define a forward diffusion process that gradually transforms the data distribution into a simple prior distribution (e.g., Gaussian noise), and second, learn the reverse generative process.</p>
<p><strong>The Forward Process: Analytically Tractable Diffusion Dynamics</strong><br>The forward process from data to noise is mathematically straightforward to define. It is typically defined by a Stochastic Differential Equation (SDE) with predefined parameters:<br>$$<br>\mathrm{d}X_t &#x3D; f(X_t, t)\mathrm{d}t + g(t)\mathrm{d}W_t<br>$$<br>In this equation, the drift function $f(X_t, t)$ and the diffusion function $g(t)$ together define an analytically tractable stochastic process that gradually eliminates the structural information in the data manifold. Since the dynamics of this process are predetermined, its transition kernel $p_t(x_t|x_0)$ at any time $t$ is also analytically known.</p>
<p><strong>The Reverse Process: Generative Dynamics to be Learned</strong><br>The reverse process is responsible for the generation task: sampling from the prior distribution and recovering the target data. This process can also be described by a reverse-time SDE. However, unlike the forward process, the drift term of this reverse SDE is not predefined. Instead, it depends on the score function, $\nabla_x \log p_t(x)$, of the marginal probability density $p_t(x)$ of the forward process at each time $t$. Because $p_t(x)$ is itself intractable, the reverse drift term is unknown and must be learned via a parameterized model. This constitutes the core learning problem of diffusion models.</p>
<h3 id="Score-Matching"><a href="#Score-Matching" class="headerlink" title="Score Matching"></a>Score Matching</h3><p>For a forward diffusion process described by the following SDE:<br>\begin{equation}<br>\mathrm{d}X_t &#x3D; f(X_t, t) \mathrm{d}t + g(t) \mathrm{d}W_t<br>\label{eq:forward_sde}<br>\end{equation}<br>According to the theory of stochastic processes \cite{anderson1982reverse}, there exists a corresponding reverse process that traces time backward from $T$ to $0$. This process is described by the following <strong>reverse-time SDE</strong> (see Appendix C for details):<br>\begin{equation}<br>\mathrm{d}x &#x3D; \left[f(x, t) - g(t)^2 \nabla_x \log p_t(x)\right] \mathrm{d}t + g(t) \mathrm{d}\bar{W}_t<br>\label{eq:reverse_sde}<br>\end{equation}<br>Here, $\mathrm{d}\bar{W}_t$ represents the infinitesimal increment of a standard Wiener process flowing backward in time, and $\mathrm{d}t$ represents an infinitesimal negative time step.</p>
<p>According to the analytical form of the reverse SDE, Eq.~\eqref{eq:reverse_sde}, the drift term of the generative process is jointly determined by the predefined functions $f(x,t)$, $g(t)$, and the key unknown term: the <strong>score function</strong>, $\nabla_x \log p_t(x)$. Therefore, the task of learning the generative model is transformed into the problem of how to effectively estimate this score function.</p>
<p>Directly computing the marginal score function $\nabla_x \log p_t(x)$ is analytically intractable. The fundamental reason is that the marginal probability density $p_t(x)$ is obtained by integrating (i.e., marginalizing) the conditional probability density $p_t(x|x_0)$ over the entire unknown true data distribution $p_{\text{data}}(x_0)$:<br>\begin{equation}<br>p_t(x) &#x3D; \int p_t(x_t|x_0)p_{\text{data}}(x_0)\mathrm{d}x_0<br>\end{equation}<br>This integral depends on $p_{\text{data}}$, which makes it impossible to compute directly. However, a key insight is that although the marginal score function is intractable, the <strong>conditional score function</strong> $\nabla_x \log p_t(x_t|x_0)$ is analytically known. This is because the forward noising process $p_t(x|x_0)$ is determined by the SDE that we predefined.</p>
<p>Fortunately, a precise mathematical relationship exists between the conditional score function $\nabla_x \log p_t(x_t|x_0)$ and the marginal score function $\nabla_x \log p_t(x)$. We can derive this relationship by starting from the definition of the marginal score function and applying Bayes‚Äô theorem:</p>
<p>$$<br>\begin{equation}<br>\begin{aligned}<br>&amp; \nabla_{x_t}\log p_t(x_t) &#x3D; \frac{\nabla_{x_t}p_t(x_t)}{p_t(x_t)} \\<br>&amp;&#x3D; \frac{1}{p_t(x_t)} \nabla_{x_t} \int p_t(x_t|x_0) p_{\text{data}}(x_0) \mathrm{d}x_0 \nonumber \\<br>&amp;&#x3D; \frac{1}{p_t(x_t)} \int \nabla_{x_t} p_t(x_t|x_0) p_{\text{data}}(x_0) \mathrm{d}x_0 \quad (\text{using the Leibniz integral rule}) \nonumber \\<br>&amp;&#x3D; \frac{1}{p_t(x_t)} \int \left( \nabla_{x_t} \log p_t(x_t|x_0) \right) p_t(x_t|x_0) p_{\text{data}}(x_0) ,\mathrm{d}x_0 \quad ( \nabla p &#x3D; p \nabla \log p) \nonumber \\<br>&amp;&#x3D; \int \left( \nabla_{x_t} \log p_t(x_t|x_0) \right) \frac{p_t(x_t|x_0) \ p_{\text{data}}(x_0)}{p_t(x_t)} \ \mathrm{d}x_0 \nonumber \\<br>&amp;&#x3D; \int \left( \nabla_{x_t} \log p_t(x_t|x_0) \right) p_t(x_0|x_t) , \mathrm{d}x_0 \quad (\text{by Bayes‚Äô theorem}) \nonumber \\<br>&amp;&#x3D; ùîº_{p_t(x_0|x_t)} \left[ \nabla_{x_t} \log p_t(x_t|x_0) \right]<br>\end{aligned}<br>\label{eq:score_identity_revised}<br>\end{equation}<br>$$</p>
<p>Eq.~\eqref{eq:score_identity_revised} shows that the marginal score function is the expectation of the conditional score function with respect to the posterior probability distribution $p_t(x_0|x)$. This important relationship transforms the problem of estimating a complex, intractable marginal score function into one of estimating a simpler, tractable conditional score function. Therefore, we can train a parameterized network $s_\theta(x, t)$ to approximate the conditional score function $\nabla_x \log p_t(x|x_0)$ over all times $t$ and data points $x_0$:</p>
<p>$$<br>L_{\text{score}}(\theta) &#x3D; \left\lVert s_\theta(x_t, t) -<br>ùîº_{x_0 \sim p_t(x_0|x_t)} \left[ \nabla_{x_t} \log p_t(x_t|x_0) \right] \right\rVert^2<br>$$</p>
<p>According to <strong>Optimal Estimation Theory</strong>(See Appendix D), for an optimization problem measured by mean squared error, the conditional expectation is the optimal estimator. In this context, the marginal score function $\nabla_{x_t}\log p_t(x_t)$ is precisely the optimal mean squared error estimate of the conditional score $\nabla_{x_t} \log p_t(x_t|x_0)$, given the noisy sample $x_t$. This conclusion reveals a critical equivalence: a loss function designed to fit the intractable marginal score (i.e., $ùîº_{x_0 \sim p_t(x_0|x_t)} \left[ \nabla_{x_t} \log p_t(x_t|x_0) \right]$) and a loss function designed to fit the tractable conditional score (i.e.,  $\nabla_{x_t} \log p_t(x_t|x_0)$ ) share the exact same optimal solution.</p>
<p>Therefore, we can instead minimize the latter, which is the objective function of <strong>Denoising Score Matching (DSM)</strong>. This method trains the score network $s_\theta(x_t, t)$ by directly fitting the analytically known conditional score:</p>
<p>\begin{equation}<br>\min_{\theta} \ ùîº_{t \sim \mathcal{U}(0,T)} \<br>ùîº_{x_0 \sim p_{\text{data}}} \<br>ùîº_{x_t \sim p_t(\cdot|x_0)}<br>\left[ \left\lVert s_\theta(x_t, t) - \nabla_{x_t} \log p_t(x_t | x_0) \right\rVert^2 \right]<br>\label{eq:dsm_loss}<br>\end{equation}</p>
<h2 id="A-Unified-Dynamical-Perspective-on-Diffusion-Models-VP-SDE-VE-SDE-and-Langevin-Dynamics"><a href="#A-Unified-Dynamical-Perspective-on-Diffusion-Models-VP-SDE-VE-SDE-and-Langevin-Dynamics" class="headerlink" title="A Unified Dynamical Perspective on Diffusion Models: VP-SDE, VE-SDE, and Langevin Dynamics"></a>A Unified Dynamical Perspective on Diffusion Models: VP-SDE, VE-SDE, and Langevin Dynamics</h2><p>Modern score-based generative models are unified under a continuous-time framework defined by Stochastic Differential Equations (SDEs). The core of this framework is the construction of a diffusion process that reversibly transforms a complex data distribution into a simple prior distribution (typically Gaussian noise). From the unified perspective of SDEs, this section analyzes three principal designs for the diffusion path: the <strong>Variance Preserving SDE (VP-SDE)</strong> and the <strong>Variance Exploding SDE (VE-SDE)</strong>. It also explores their connection to classical <strong>Langevin Dynamics</strong>, aiming to reveal their commonalities and differences in terms of modeling paradigms, sampling strategies, and the application of score functions.</p>
<h3 id="VP-SDE-Variance-Preserving-Diffusion-Modeling"><a href="#VP-SDE-Variance-Preserving-Diffusion-Modeling" class="headerlink" title="VP-SDE: Variance Preserving Diffusion Modeling"></a>VP-SDE: Variance Preserving Diffusion Modeling</h3><p>The design of the VP-SDE aims to ensure that during the diffusion process, the variance of the marginal data distribution remains within a finite range. It is inspired by DDPM (Denoising Diffusion Probabilistic Models) \cite{ho2020denoising}.</p>
<p><strong>Forward Process</strong><br>The VP-SDE is defined by a linear SDE of the following form:<br>\begin{equation}<br>\mathrm{d}X_t &#x3D; -\frac{1}{2} \beta(t) X_t  \mathrm{d}t + \sqrt{\beta(t)}  \mathrm{d}W_t, \quad t \in [0, T]<br>\label{eq:vp_sde_forward}<br>\end{equation}<br>where $\beta(t) &gt; 0$ is a predefined, monotonically increasing noise schedule function. This linear SDE has an analytical solution, and its transition kernel $p_t(x_t|x_0)$, given initial data $x_0$, is a Gaussian distribution:<br>\begin{equation}<br>p_t(x_t|x_0) &#x3D; \mathcal{N}\left(x_t; \sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha}_t) \mathbf{I}\right)<br>\end{equation}<br>where $\bar{\alpha}_t &#x3D; \exp\left(-\int_0^t \beta(s) \mathrm{d}s\right)$. This formulation ensures that as $t$ goes from $0 \to T$, the influence of the initial data $x_0$ gradually diminishes while the influence of the noise gradually increases, such that $p_T(x_T)$ ultimately approximates a standard normal distribution, $\mathcal{N}(0, \mathbf{I})$.</p>
<p><strong>Reverse Process</strong><br>According to the theory of stochastic processes by Anderson (1982), the reverse-time SDE corresponding to Eq.~\eqref{eq:vp_sde_forward} exists and has the following form:</p>
<p>\begin{equation}<br>\mathrm{d}X_t &#x3D; \left[ -\frac{1}{2} \beta(t) X_t - \beta(t) \nabla_{x_t} \log p_t(x_t) \right] \mathrm{d}t + \sqrt{\beta(t)} , \mathrm{d}\bar{W}_t<br>\label{eq:vp_sde_reverse}<br>\end{equation}</p>
<p>where $\mathrm{d}t$ is an infinitesimal negative time step, and $\mathrm{d}\bar{W_t}$ is a reverse-time Wiener process. The drift term of this reverse process is composed of two parts: the drift term from the forward process, $f(x,t) &#x3D; -\frac{1}{2}\beta(t)x_t$, and a correction term based on the score function, $-g(t)^2 \nabla_{x_t} \log p_t(x_t)$. The core of the generative process is to learn a parameterized network $s_\theta(x_t, t)$ to accurately estimate the true score function.</p>
<p><strong>Discretized Sampling</strong><br>To generate samples from this model, we need to numerically discretize the reverse SDE from Eq.~\eqref{eq:vp_sde_reverse}. This is typically done by starting at $t&#x3D;T$ and stepping backward to $t&#x3D;0$. Applying the Euler-Maruyama method, a single update step from time $t_i$ to $t_{i-1}$ can be expressed as:<br>\begin{equation}<br>x_{i-1} &#x3D; x_i - \left[ -\frac{1}{2}\beta(t_i)x_i - \beta(t_i)s_\theta(x_i, t_i) \right]\Delta t + \sqrt{\beta(t_i)\Delta t} \cdot \varepsilon_i<br>\end{equation}<br>where $\Delta t &#x3D; t_i - t_{i-1} &gt; 0$ is a small positive time step, and $\varepsilon_i \sim \mathcal{N}(0, \mathbf{I})$. After rearranging, this sampling format corresponds to the predictor step of many Predictor-Corrector samplers.</p>
<h2 id="VE-SDE-Variance-Exploding-Diffusion-Modeling"><a href="#VE-SDE-Variance-Exploding-Diffusion-Modeling" class="headerlink" title="VE-SDE: Variance Exploding Diffusion Modeling"></a>VE-SDE: Variance Exploding Diffusion Modeling</h2><p>The design of the VE-SDE (Variance Exploding SDE) originates from early score-based generative models. It is characterized by the fact that during the diffusion process, the variance of the data distribution continuously increases, eventually covering the entire space.</p>
<p><strong>Forward Process</strong><br>The VE-SDE is an SDE with no drift term, defined as follows:<br>\begin{equation}<br>\mathrm{d}X_t &#x3D; \sigma(t) , \mathrm{d}W_t, \quad t \in [0, T]<br>\end{equation}<br>where $\sigma(t)$ is a diffusion coefficient function that increases with time. The transition kernel $p_t(x_t|x_0)$ of this SDE is also a Gaussian distribution, but its mean remains unchanged:<br>\begin{equation}<br>p_t(x_t|x_0) &#x3D; \mathcal{N}\left(x_t; x_0, \left[\int_0^t \sigma^2(s)\mathrm{d}s\right] \mathbf{I}\right)<br>\end{equation}<br>As $t \to T$, the variance term $\int_0^t \sigma^2(s)\mathrm{d}s \to \infty$, hence the name ‚ÄúVariance Exploding.‚Äù</p>
<p><strong>Reverse Process</strong><br>The corresponding reverse-time SDE does not contain a structural drift term and has the form:<br>\begin{equation}<br>\mathrm{d}X_t &#x3D; - \sigma(t)^2 \nabla_{x_t} \log p_t(x_t) , \mathrm{d}t + \sigma(t) , \mathrm{d}\bar{W_t}<br>\label{eq:ve_sde_reverse}<br>\end{equation}<br>The generative process likewise depends on an accurate estimation of the score function, $\nabla_{x_t} \log p_t(x_t)$.</p>
<p><strong>Discretized Sampling</strong><br>Applying the Euler-Maruyama method to Eq.~\eqref{eq:ve_sde_reverse} yields the following discrete sampling update rule:<br>\begin{equation}<br>x_{i} &#x3D; x_{i+1} + \sigma(t_{i+1})^2 s_\theta(x_{i+1}, t_{i+1}) |\Delta t| + \sqrt{\sigma(t_{i+1})^2 |\Delta t|} \cdot \varepsilon_i<br>\end{equation}<br>where $s_\theta$ is the trained score network and $\Delta t &#x3D; t_i - t_{i+1} &gt; 0$.</p>
<h2 id="Langevin-Dynamics-as-a-Unifying-Perspective"><a href="#Langevin-Dynamics-as-a-Unifying-Perspective" class="headerlink" title="Langevin Dynamics as a Unifying Perspective"></a>Langevin Dynamics as a Unifying Perspective</h2><p>Although the reverse processes of VP-SDE and VE-SDE differ in form, they can both be viewed as generalizations of classical Langevin Dynamics under different settings.</p>
<p><strong>Classical Langevin Dynamics</strong><br>Langevin dynamics originates from statistical physics and is used to sample from a given probability density function $p(x)$. Its SDE form is:<br>\begin{equation}<br>\mathrm{d}X_t &#x3D; \frac{1}{2}\nabla_x \log p(x) , \mathrm{d}t + \mathrm{d}W_t<br>\end{equation}<br>The stationary distribution of this process is the target distribution $p(x)$. Its discrete form, the Langevin sampling algorithm, iterates as follows:<br>$$<br>x_{k+1} &#x3D; x_k + \frac{\eta}{2} \nabla_x \log p(x_k) + \sqrt{\eta} \cdot \varepsilon_k<br>$$<br>In score-based generative models, iteratively applying Langevin sampling steps at different noise scales constitutes the Annealed Langevin Sampling algorithm.</p>
<p><strong>Structural Mapping and Unification</strong><br>We can uniformly represent the reverse processes of both VP-SDE and VE-SDE as a form of generalized Langevin dynamics. A generalized overdamped Langevin SDE can be written as:<br>$$<br>\mathrm{d}X_t &#x3D; -\nabla_x U(x_t, t) , \mathrm{d}t + \sqrt{2D(t)} , \mathrm{d}W_t<br>$$<br>where $U(x,t)$ is a time-dependent potential energy function, and $D(t)$ is a time-varying diffusion constant. For a probability density $p_t(x)$, the relationship between the potential and the density is given by $\nabla_x \log p_t(x) &#x3D; -\frac{1}{2D(t)}\nabla_x U(x, t)$.</p>
<p><strong>Equivalence of VE-SDE and Langevin Dynamics</strong><br>The reverse process of the VE-SDE, Eq.~\eqref{eq:ve_sde_reverse},<br>$$<br>\mathrm{d}X_t &#x3D; - \sigma(t)^2 \nabla_{x_t} \log p_t(x_t) , \mathrm{d}t + \sigma(t) , \mathrm{d}\bar{W}_t<br>$$<br>can be seen as a time-scaled Langevin dynamics. Its drift term is guided entirely by the score function and contains no additional structural drift.</p>
<p><strong>Relationship between VP-SDE and Langevin Dynamics</strong><br>The reverse process of the VP-SDE, Eq.~\eqref{eq:vp_sde_reverse},<br>$$<br>\mathrm{d}X_t &#x3D; \left[ -\frac{1}{2} \beta(t) X_t - \beta(t) \nabla_{x_t} \log p_t(x_t) \right] \mathrm{d}t + \sqrt{\beta(t)} , \mathrm{d}\bar{W}_t<br>$$<br>can be decomposed into two parts: a structural drift term, $f(x,t) &#x3D; -\frac{1}{2}\beta(t)x_t$, and a score-guided term. Therefore, the VP-SDE can be regarded as a generalized Langevin dynamics with an additional structural drift.<br><img src="/pic/2.png" alt="ËøôÊòØÂõæÁâáËØ¥Êòé"></p>
<h2 id="Removing-Randomness-Degeneration-from-SDE-to-the-Probability-Flow-ODE"><a href="#Removing-Randomness-Degeneration-from-SDE-to-the-Probability-Flow-ODE" class="headerlink" title="Removing Randomness: Degeneration from SDE to the Probability Flow ODE"></a>Removing Randomness: Degeneration from SDE to the Probability Flow ODE</h2><p>The numerical discretization of an SDE, such as the Euler-Maruyama method, has the following iterative formula:<br>$$<br>x_{i+1} &#x3D; x_i + \mu(x_i, t_i)h + \sigma(t_i)\sqrt{h} \cdot \varepsilon_i, \quad \varepsilon_i \sim \mathcal{N}(0, \mathbf{I})<br>$$<br>The presence of the stochastic term $\sigma(t_i)\sqrt{h} \cdot \varepsilon_i$ causes the sampling trajectories of the SDE to exhibit random fluctuations. To ensure numerical stability and accurately approximate the true solution, the time step $h$ must be sufficiently small, which leads to a large number of sampling steps and consequently, low generation efficiency.</p>
<p>To overcome this limitation, an equivalent deterministic process can be sought, whose trajectories are described by an Ordinary Differential Equation (ODE), yet which generates marginal probability density functions, $p_t(x)$, identical to those of the original SDE. This implies that although the individual trajectories of the ODE are deterministic, if a large number of points are sampled from the entire prior distribution, $p_T(x)$, and evolved according to the ODE, their spatial distribution at any given time $t$ will be identical to the particle ensemble distribution resulting from the SDE‚Äôs evolution. This equivalent ODE is known as the <strong>Probability Flow ODE</strong>:</p>
<p>$$<br>\begin{equation}<br>\begin{aligned}<br>\frac{\partial p(x, \tau)}{\partial \tau}<br>&amp;&#x3D; \nabla_x \cdot [f(x, \tau) p(x, \tau)] - \frac{g(\tau)^2}{2} \nabla_x^2 p(x, \tau)\\<br>&amp;&#x3D; \nabla_x \cdot [f(x, \tau) p(x, \tau)]- \frac{g(\tau)^2}{2} \nabla_x \cdot (\nabla_x p(x, \tau))\\<br>&amp;&#x3D;\nabla_x \cdot \left[f(x, \tau) p(x, \tau) - \frac{g(\tau)^2}{2} \nabla_x p(x, \tau) \right]\\<br>&amp;&#x3D;\nabla_x \cdot \left[ f(x, \tau) p(x, \tau) - \frac{g(\tau)^2}{2} \left(p(x, \tau) \cdot \nabla_x \log p(x, \tau) \right) \right]\\<br>&amp;&#x3D;- \nabla_x \cdot \left[ \left(-f(x, \tau) + \frac{g(\tau)^2}{2} \nabla_x \log p(x, \tau) \right) p(x, \tau) \right]<br>\end{aligned}<br>\end{equation}<br>$$</p>
<p>This equation describes the probability density evolution of a deterministic process. By comparing this to the form of the FPE without a stochastic term, Eq.~\ref{eq:ode_FPE}, we can identify the corresponding velocity field (or drift term) for the ODE as:<br>\begin{equation}<br>\mu(x,t) &#x3D; f(x, t) - \frac{1}{2}g(t)^2 \nabla_x \log p(x, t)<br>\end{equation}<br>Therefore, the Probability Flow ODE that shares the same marginal probability densities as the forward SDE is:<br>\begin{equation}<br>\mathrm{d}x &#x3D; \left[ f(x, t) - \frac{1}{2}g(t)^2 \nabla_x \log p_t(x) \right] \mathrm{d}t<br>\end{equation}<br>In generative modeling, we use a neural network $s_\theta(x,t)$ to approximate the score function $\nabla_x \log p_t(x)$. By integrating the above ODE backward in time (from $T$ to $0$), we can deterministically generate data from noise.</p>
<p><img src="/pic/3.png" alt="ËøôÊòØÂõæÁâáËØ¥Êòé"></p>
<p>The deterministic nature of the Probability Flow ODE enables efficient, high-order numerical solvers (e.g., Runge-Kutta) that can generate high-quality samples in very few steps, forming the basis for fast algorithms like DDIM \cite{song2020denoising}. This reveals a profound SDE-ODE duality: although both processes share the same macroscopic evolution of marginal densities$p_t(x)$, their microscopic paths differ fundamentally. SDE trajectories are stochastic and irregular, while ODE trajectories are smooth and unique, a contrast visualized in Fig.3.</p>
<figure id="fig-sde-vs-ode" style="text-align:center;">
  <img src="/pic/4.png" alt="SDE vs ODE" style="max-width:80%;">
  <figcaption style="text-align:justify; font-size:90%;">
    <b>Fig.3Ôºö</b> <strong>Comparison of SDE and Probability Flow ODE Paths. (Song et al., 2021)</strong><br>
    This figure illustrates the forward process from the data distribution 
    \(p_0(x)\) to the prior distribution \(p_T(x)\), as well as the reverse process of recovering data from the prior. 
    The background heatmap represents the spatiotemporal evolution of the marginal probability density \(p_t(x)\). 
    The colorful, jagged curves in the figure are random sample paths generated by an SDE solver (e.g., the Euler-Maruyama method), 
    while the smooth white curves are the deterministic paths generated by the corresponding Probability Flow ODE. 
    The ODE paths evolve precisely along the 'ridges' or peak regions of the probability density.
  </figcaption>
</figure>






<h1 id="Flow-Based-Models"><a href="#Flow-Based-Models" class="headerlink" title="Flow-Based Models"></a>Flow-Based Models</h1><p>After an in-depth exploration of diffusion models, which are centered on stochastic processes, this section shifts its focus to another powerful generative modeling paradigm:<strong>Flow-Based Models</strong>. Unlike diffusion models, which connect data and noise by simulating a stochastic process, flow-based models aim to learn a deterministic and invertible transformation. This transformation can precisely map a simple prior distribution (e.g., a Gaussian) to a complex target data distribution.</p>
<p>This process can be conceptualized as learning a vector field defined by an Ordinary Differential Equation (ODE). Guided by this vector field, data points, like massless particles, smoothly ‚Äòflow‚Äô from a simple region of space to the complex region where the data manifold resides. This chapter will begin with classical <strong>Normalizing Flows</strong>, progressively reveal their inherent limitations, and show how they naturally evolve into the ODE-based <strong>Continuous Normalizing Flows</strong>, ultimately leading to a more training-efficient modern paradigm: <strong>Flow Matching</strong>.</p>
<h2 id="The-Classic-Paradigm-Normalizing-Flows"><a href="#The-Classic-Paradigm-Normalizing-Flows" class="headerlink" title="The Classic Paradigm: Normalizing Flows"></a>The Classic Paradigm: Normalizing Flows</h2><p>Normalizing Flows (NF) \cite{rezende2015variational} are a foundational work in the flow-based modeling paradigm. Their core mechanism is to map a complex data distribution $p_X(x)$ to a simple base distribution $p_Z(z)$ through a series of invertible transformations $f_1, f_2, \dots, f_M$; a process that is both mathematically clear and elegant.</p>
<p>Their mathematical foundation is the change of variables formula from probability theory. For an invertible transformation $z &#x3D; f(x)$, the relationship between the probability densities is:<br>\begin{equation}<br>p_X(\boldsymbol{x}) &#x3D; p_Z(f(\boldsymbol{x})) \left| \det\left( \frac{\partial f(\boldsymbol{x})}{\partial \boldsymbol{x}} \right) \right|<br>\end{equation}<br>where $\frac{\partial f(x)}{\partial x}$ is the Jacobian matrix of the transformation, and the absolute value of its determinant, $|\det(\cdot)|$, measures the stretching or compression of an infinitesimal volume element by the transformation. This factor is the critical ‚Äònormalizing‚Äô term that ensures the transformed probability density function still integrates to 1.</p>
<p>Because the expressive power of a single transformation is limited, NFs typically concatenate multiple simple, invertible transformations $f_i$ to form a ‚Äòflow‚Äô. The calculation of its log-likelihood depends on the sum of the log-determinants of the Jacobians:<br>\begin{equation}<br>\log p_X(x) &#x3D; \log p_Z(f_M(\dots f_1(x)\dots)) + \sum_{i&#x3D;1}^{M} \log \left| \det\left( \mathbf{J}_{f_i} \right) \right|<br>\end{equation}</p>
<p>Behind the simplicity of this formula lie the core design constraints of NF models. To ensure the model is computationally feasible, each transformation layer $f_i$ must be carefully designed to simultaneously satisfy two demanding conditions:</p>
<ul>
<li><strong>Invertibility</strong>: The transformation must be bijective.</li>
<li><strong>Efficient Jacobian Determinant</strong>: The computation of the Jacobian determinant, $|\det(\mathbf{J}_{f_i})|$, must be efficient (e.g., with a computational complexity of $\mathcal{O}(D)$ instead of $\mathcal{O}(D^3)$).</li>
</ul>
<p>The second condition severely restricts the available neural network architectures and has given rise to models such as RealNVP and Glow, which use specially designed coupling layers. However, this structural compromise, made for the sake of computational efficiency, undoubtedly also limits the model‚Äôs expressive power.</p>
<h2 id="From-Discrete-to-Continuous-Continuous-Normalizing-Flows"><a href="#From-Discrete-to-Continuous-Continuous-Normalizing-Flows" class="headerlink" title="From Discrete to Continuous: Continuous Normalizing Flows"></a>From Discrete to Continuous: Continuous Normalizing Flows</h2><p>A solution to the aforementioned limitations lies in reconceptualizing the nature of the transformation from a discrete hierarchy to a continuous process. If we imagine an NF with an infinite number of layers, where each layer applies only an infinitesimal transformation to the data, then the limit of this process is a continuous-time flow parameterized by time. This is the core idea behind \textbf{Continuous Normalizing Flows (CNF)}.</p>
<p>In the CNF framework, the transformation is no longer defined by a discrete sequence of functions ${f_i}$, but is instead described by a continuous trajectory $z(t)$ governed by an Ordinary Differential Equation (ODE):<br>\begin{equation}<br>\frac{\mathrm{d}z(t)}{\mathrm{d}t} &#x3D; f(z(t), t, \theta), \quad \text{with initial condition } z(0) &#x3D; x<br>\end{equation}<br>From this perspective, the neural network $f$ no longer directly defines a transformation, but instead defines the instantaneous velocity vector field for a data point at any position $z(t)$ and time $t$.</p>
<p>This change in perspective brings a critical breakthrough for likelihood computation. In the continuous limit, the sum of the log-determinants of the Jacobians in the discrete NF log-likelihood formula becomes an integral of the \textbf{trace} of the Jacobian matrix. According to the instantaneous change of variables formula, the log-likelihood of a CNF can be expressed as:<br>\begin{equation}<br>\log p_X(x) &#x3D; \log p_Z(z(T)) - \int_0^T \text{Tr}\left(\frac{\partial f(z(t), t)}{\partial z(t)}\right) \mathrm{d}t<br>\end{equation}<br>The shift from ‚Äúdeterminant‚Äù to ‚Äútrace‚Äù is significant because it greatly relaxes the constraints on the neural network architecture (the computational complexity of the trace is typically $\mathcal{O}(D)$). However, this theoretical elegance shifts the computational burden to the training phase. To evaluate the likelihood of any data point $x$, two computationally expensive operations must be performed:</p>
<ul>
<li>Starting from $z(0) &#x3D; x$, integrate the ODE fully using a numerical solver to obtain the final state $z(T)$.</li>
<li>While solving the ODE, one must also compute and integrate the trace of the Jacobian along the entire trajectory.</li>
</ul>
<p>These two steps make the training process for CNFs slow, prompting researchers to seek new paradigms that can both retain the powerful expressiveness of the ODE framework and achieve efficient training.</p>
<h2 id="A-Modern-Paradigm-for-Efficient-Training-Flow-Matching"><a href="#A-Modern-Paradigm-for-Efficient-Training-Flow-Matching" class="headerlink" title="A Modern Paradigm for Efficient Training: Flow Matching"></a>A Modern Paradigm for Efficient Training: Flow Matching</h2><p>The idea behind Flow Matching (FM) \cite{lipman2022flow} is highly insightful: instead of indirectly optimizing the vector field by computing the probability densities at the two ends of a trajectory, we directly learn a vector field $u_t^\theta(x)$ to construct a deterministic flow via an ODE that moves from a simple noise distribution to a complex data distribution:<br>$$<br>x_0\sim p_0, \quad \frac{dx_t}{dt}&#x3D;u_t^\theta(x)<br>$$</p>
<p>Assume there exists an ideal vector field $u_t(x)$ that can transport the source distribution $p_0$ to the target data distribution $p_1$. The objective of Flow Matching is to train a neural network $u_\theta(\boldsymbol{x}, t)$ to directly regress this target field:<br>$$<br>L(\theta) &#x3D; \mathbb{E}[||u_t^{\theta}(x) - u_t^{\text{true}}(x)||^2]<br>$$</p>
<p>However, the true marginal vector field $u_t^{\text{true}}(x)$ and the marginal probabilities along the path, $p_t^{\text{true}}(x)$, are both unknown.</p>
<h3 id="Conditional-Flow-Matching"><a href="#Conditional-Flow-Matching" class="headerlink" title="Conditional Flow Matching"></a>Conditional Flow Matching</h3><p>We encountered a similar challenge in diffusion models: the marginal score function $\nabla_{x_t}\log p_t(x_t)$ was intractable, so we instead used the tractable conditional score function $\nabla_{x_t}\log p_t(x_t|x_0)$ and proved the identity in Eq.~\eqref{eq:score_identity_revised}. Here, we will adopt the exact same philosophical approach: we derive the marginal vector field $u_t^{\text{true}}(x)$ by constructing a conditional vector field $u_t^{\text{true}}(x|z)$:</p>
<p>\begin{align*}<br>u_t^{\text{target}}(x)<br>&amp;&#x3D; \int u_t^{\text{target}}(x|z) p_t(z|x) , \mathrm{d}z \\<br>&amp;&#x3D; \int u_t^{\text{target}}(x|z) \frac{p_t(x|z) p^{\text{data}}(z)}{p_t(x)} , \mathrm{d}z\\<br>&amp;&#x3D;\mathbb{E}_{z \sim p_t(z|x)} \left[ u_t^{\text{target}}(x \mid z) \right]<br>\end{align*}<br>By definition, for any probability flow generated by the vector field $u_t(x)$, its probability density $p_t(x)$ must satisfy the continuity equation:</p>
<p>$$<br>\begin{aligned}<br>\frac{\partial p_t(x)}{\partial t}<br>&amp;&#x3D; -\mathrm{div} \left( p_t(x) \cdot u_t^{\text{target}}(x) \right) \\<br>&amp;&#x3D; -\mathrm{div} \left( \int p_t(x|z) p_{\text{data}}(z) u_t^{\text{target}}(x|z) , dz \right) \\<br>&amp;&#x3D; -\mathrm{div} \left( \int p_t(x|z) u_t^{\text{target}}(x|z) p_{\text{data}}(z) , dz \right) \\<br>&amp;&#x3D; -\mathrm{div} \left( p_t(x) \int u_t^{\text{target}}(x|z) \frac{p_t(x|z) p_{\text{data}}(z)}{p_t(x)} , dz \right)<br>\end{aligned}<br>$$<br>So,<br>\begin{equation}<br>u_t^{\text{target}}(x) &#x3D; \int u_t^{\text{target}}(x|z) \frac{p_t(x|z) p_{\text{data}}(z)}{p_t(x)} , dz&#x3D;\mathbb{E}_{z \sim p_t(z|x)} \left[ u_t^{\text{target}}(x|z) \right]\label{eq:33}<br>\end{equation}</p>
<p>This is a classic posterior expectation form, which indicates that at a given position $x$ and time $t$, the marginal vector field $u_t^{\text{target}}(x)$ can be viewed as the expectation of the conditional vector field $u_t^{\text{target}}(x|z)$ under the posterior distribution $p_t(z|x)$. This relationship is highly significant: it shows that although the true marginal vector field $u_t(x)$ cannot be obtained explicitly, we can design conditional path distributions $p_t(x|z)$ that are easy to sample from and compute. Combined with training data $z \sim p_{\text{data}}(z)$, this allows us to estimate this expectation via Monte Carlo methods during training, thereby fitting the marginal vector field.</p>
<p>Furthermore, we note that this formula essentially originates from Bayes‚Äô theorem:<br>\begin{equation*}<br>p_t(z \mid x) &#x3D; \frac{p_t(x \mid z) \cdot p_{\text{data}}(z)}{p_t(x)}<br>\end{equation*}</p>
<p>Therefore, the expression for the marginal vector field can also be interpreted as follows: the marginal vector field is a weighted average of the conditional vector fields $u_t(x|z)$ defined by all possible target states $z$, where the weights are proportional to the likelihood that state $z$ generated the current point $x$.</p>
<p>Furthermore, based on the core identity from Eq.~\eqref{eq:33}, a theoretically ideal objective would be to train a parameterized vector field network $u_\theta(x, t)$ to directly regress the true marginal vector field $u_t(x)$. This can be formalized as minimizing the following loss function:</p>
<p>\begin{equation}<br>\mathcal{L}_{\text{marginal}}(\theta) &#x3D; \mathbb{E}_{t \sim \mathcal{U}(0,1), x \sim p_t(x)} \left[ \left\Vert u_\theta(x, t) - u_t(x) \right\Vert^2 \right]<br>\label{eq:35}<br>\end{equation}</p>
<p>However, this objective function is computationally intractable. The fundamental reason is that the target, $u_t(x) &#x3D; \mathbb{E}_{z \sim p_t(z|x)} [u_t(x|z)]$, is an expectation under the unknown posterior probability distribution $p_t(z|x)$, which in turn depends on the unknown data prior $p_{\text{data}}(z)$ and the intractable marginal distribution $p_t(x)$.</p>
<p>To construct a tractable learning objective, <strong>Conditional Flow Matching (CFM)</strong> proposes to instead regress the more tractable <strong>conditional vector field</strong> $u_t(x|z)$. Based on the principle of optimal estimation (see Appendix D), its loss function is defined as:<br>\begin{equation}<br>\mathcal{L}_{\text{CFM}}(\theta) &#x3D; \mathbb{E}_{t \sim \mathcal{U}(0,1), z \sim p_{\text{data}}(z), x \sim p_t(x|z)} \left[ \left| u_\theta(x, t) - u_t(x|z) \right|^2 \right]<br>\label{eq:36}<br>\end{equation}<br>Alternatively, the equivalence of Eq.<del>\ref{eq:35} and Eq.</del>\ref{eq:36} can be proven from a gradient optimization perspective, as shown in Appendix E.</p>
<h2 id="Gaussian-Probability-Paths"><a href="#Gaussian-Probability-Paths" class="headerlink" title="Gaussian Probability Paths"></a>Gaussian Probability Paths</h2><p>To concretely illustrate the conditional vector field and its induced probability paths, we construct a special case where the conditional path $p_t(x|x_1)$ follows a Gaussian distribution:<br>\begin{equation}<br>p_t(x_t | x_1) &#x3D; \mathcal{N}(x_t; \mu_t(x_1), \sigma_t(x_1)^2 \mathbf{I})<br>\label{eq:37}<br>\end{equation}<br>where $\mu_t(x_1)$ and $\sigma_t(x_1)$ are the conditional mean and standard deviation of the path at time $t$, respectively. A conditional vector field $u_t(x|x_1)$ capable of generating this Gaussian path has the following analytical form (for a proof, see Appendix F):<br>\begin{equation}<br>u_t(x | x_1) &#x3D; \frac{\dot{\sigma}_t(x_1)}{\sigma_t(x_1)} (x - \mu_t(x_1)) + \dot{\mu}_t(x_1)<br>\label{eq:general_gaussian_vf}<br>\end{equation}</p>
<p>\paragraph{Linear Interpolation}<br>We can choose a simple functional form for the mean and standard deviation of this Gaussian path, namely, linear interpolation:<br>\begin{align*}<br>\mu_t(x_1) &amp;\triangleq tx_1 \\<br>\sigma_t(x_1) &amp;\triangleq (1-t) + t\sigma_{\min}<br>\end{align*}<br>Their corresponding time derivatives are $\dot{\mu}_t(x_1) &#x3D; x_1$ and $\dot{\sigma}_t(x_1) &#x3D; -1 + \sigma_{\min}$. Substituting these terms into Eq.~\eqref{eq:general_gaussian_vf} yields the expression for the conditional vector field under this specific linear interpolation path:<br>\begin{align*}<br>u_t(x \mid x_1)<br>&amp;&#x3D; \frac{-(1 - \sigma_{\min})}{1 - (1 - \sigma_{\min})t} (x - tx_1) + x_1 \\<br>&amp;&#x3D; \frac{1}{(1 - t) + t \sigma_{\min}} \left( - (1 - \sigma_{\min})(x - tx_1) + \left(1 - (1 - \sigma_{\min})t \right)x_1 \right) \\<br>&amp;&#x3D; \frac{1}{(1 - t) + t \sigma_{\min}} \left( - (1 - \sigma_{\min})x + x_1 \right) \\<br>&amp;&#x3D; \frac{x_1 - (1 - \sigma_{\min})x}{1 - (1 - \sigma_{\min})t}<br>\end{align*}</p>
<p>To intuitively demonstrate the difference in paths generated by the conditional vector field $u_t(x|x_1)$ and its corresponding marginal vector field $u_t(x)$, we construct a Gaussian-to-ring transformation task. Let the initial distribution be a Gaussian distribution centered at the origin, $p_0 &#x3D; \mathcal{N}(\mathbf{0}, \sigma_0^2\mathbf{I})$, and the target distribution be a ring distribution centered at the origin with radius $R$, denoted as $p_1$.</p>
<p>According to the core identity of Flow Matching, at any intermediate time $t$ and any position $x_t$, the marginal vector field $u_t(x_t)$ is the expectation of all possible conditional vector fields $u_t(x_t|x_1)$ under the posterior probability $p_t(x_1|x_t)$. However, since the target point $x_1$ is not uniquely determined, we obtain the marginal vector field by weighting all possible conditional vector fields $u_t(x \mid x_1)$ by the Bayesian posterior $p_t(x_1 \mid x)$:<br>\begin{align*}<br>u_t\left(\phi_t(x_0)\right) &amp;&#x3D; \mathbb{E}_{x_1 \sim p_t(x_1|x_t)} \left[ u_t\left( x_t \mid x_1 \right) \right]\\<br>&amp;\approx \frac{1}{n} \sum_{i&#x3D;1}^n u_t\left(x_t \mid x_1^{(i)}\right)<br>\quad \text{with } x_1^{(i)} \sim p_{1|t}\left(x_1 \mid x_t\right).<br>\end{align*}</p>
<figure id="fig-sde-vs-ode" style="text-align:center;">
  <img src="/pic/5.png" alt="SDE vs ODE" style="max-width:80%;">
  <figcaption style="text-align:justify; font-size:90%;">
    <b>Fig.4Ôºö</b> <strong>Visual comparison of conditional and marginal paths in the Gaussian-to-Ring example.</strong> <strong>(Left)</strong> Conditional paths $\phi_t(x_0|x_1)$ driven by the conditional vector field $u_t(x|x_1)$. Each path corresponds to a linear interpolation between a starting point $x_0$ randomly sampled from $p_0$ and an endpoint $x_1$ randomly sampled from $p_1$. Due to the random pairing, the paths exhibit significant crossing. <strong>(Right)</strong> Marginal paths $\phi_t(x_0)$ driven by the marginal vector field $u_t(x)$. These paths are the result of averaging over all possible endpoints $x_1$, weighted by their posterior probabilities. The paths are smooth and do not intersect, which is consistent with the uniqueness theorem for solutions to Ordinary Differential Equations (ODEs).
  </figcaption>
</figure>


<p>However, to reveal at a more microscopic level how the smoothness of the marginal vector field $u_t(x)$ arises from statistical averaging, it is necessary to examine its instantaneous dynamical properties. By its definition, $u_t(x) &#x3D; \mathbb{E}_{p_t(x_1|x_t)}[u_t(x|x_1)]$, the properties of this vector field at each moment in time $t$ are determined by the posterior distribution $p_t(x_1|x_t)$. Predictably, as the particle‚Äôs state $x_t$ approaches the target distribution $p_1$, the posterior distribution $p_t(x_1|x_t)$ will contract significantly. Fig.5  aims to clarify this phenomenon of posterior contraction by visualizing the vector fields at two different moments in time, revealing how it leads to a reduction in the variance of the conditional vector fields and thereby enhances the stability of the marginal vector field.</p>
<figure id="fig-sde-vs-ode" style="text-align:center;">
  <img src="/pic/6.png" alt="SDE vs ODE" style="max-width:60%;">
  <figcaption style="text-align:justify; font-size:90%;">
    Fig.5ÔºöA comparison of the marginal vector field \( u_t(x) \) and the conditional vector fields \( u_t(x \mid x_1) \) at different time steps, visualizing the effect of posterior distribution contraction on the stability of the vector field.
  </figcaption>
</figure>







<h2 id="Coupling"><a href="#Coupling" class="headerlink" title="Coupling"></a>Coupling</h2><p>An intrinsic challenge arises when training Conditional Flow Matching: for small values of $t$, the conditional vector field $u_t(x_t|x_1)$ constructed by the default <strong>independent coupling</strong> strategy exhibits high variance, leading to training instability.</p>
<p>The root cause is that independent coupling pairs a starting point $x_0 \sim p_0$ with an endpoint $x_1 \sim p_1$ while completely disregarding their geometric relationship. When the two distributions are geometrically mismatched (e.g., a Gaussian to a ring distribution), this strategy generates a multitude of chaotic and conflicting conditional paths. This ultimately results in high variance in the loss function‚Äôs gradient estimates, thereby impeding the training process.</p>
<p>Therefore, a natural idea is to design a more intelligent coupling scheme to fundamentally reduce the intrinsic variance of the conditional vector fields. This constitutes the core of this section. We will explore the evolution from simple independent coupling to the geometry-aware <strong>Optimal Transport Coupling</strong>, aiming to construct more orderly and less conflicting conditional paths, thereby significantly improving training stability and efficiency.</p>
<p><strong>One-Sided Conditioning</strong><br>An initial and more direct method for constructing the vector field is to condition on data points $x_1$ sampled from the target distribution and subsequently marginalize over this distribution. This paradigm is known as one-sided conditioning.</p>
<p>The marginal probability path $p_t(x_t)$ is defined by marginalizing the conditional probability path $p_t(x_t | z)$ over the latent variable $z&#x3D;x_1$, where $x_1$ is sampled from the data distribution $p_{\text{data}}(x_1)$. This relationship can be expressed as:<br>\begin{equation} \label{eq:one_sided_en}<br>p_t(x_t) &#x3D; \int p_t(x_t | z) p_{\text{data}}(z) dz &#x3D; \int p_t(x_t | x_1) p_{\text{data}}(x_1) dx_1<br>\end{equation}<br>A typical example of such a conditional path is a time-varying Gaussian distribution centered at the target point $x_1$. For instance:<br>\begin{equation}<br>p(x_t | x_1) &#x3D; \mathcal{N}(x_t | x_1, (1-t)^2\mathbf{I})<br>\end{equation}</p>
<p><strong>Two-Sided Conditioning</strong><br>A more general and powerful framework is to condition on a latent variable $z$ that contains information about \textit{both endpoints} of the trajectory. This method is known as two-sided conditioning. This latent variable is defined as the pair of points $z &#x3D; (x_1, x_0)$.</p>
<p>Under this paradigm, the marginal probability path is defined by marginalizing over the joint distribution, or coupling, $p_{\text{data}}(x_1, x_0)$:<br>\begin{equation} \label{eq:two_sided_en}<br>p_t(x_t) &#x3D; \iint p_t(x_t | z) p_{\text{data}}(z) dz &#x3D; \iint p_t(x_t | x_1, x_0) p_{\text{data}}(x_1, x_0) dx_1 dx_0<br>\end{equation}</p>
<figure id="fig-sde-vs-ode" style="text-align:center;">
  <img src="/pic/7.png" alt="SDE vs ODE" style="max-width:70%;">
  <figcaption style="text-align:justify; font-size:90%;">
    <b>Fig.6Ôºö</b> <strong>Comparison and Application Example of One-Sided vs. Two-Sided Conditioning in CFM:</strong> <strong>(Left)</strong>
    The evolution of the path is guided entirely by the final configuration $x_1$, while its starting point $x_0$ is a random noise distribution. The goal is to create an ordered structure from chaos. <strong>(Right)</strong>
    The path is a direct bridge connecting a specific initial state $x_0$ (e.g., an initial guess based on the centroid) to the final state $x_1$. Its stronger control over the path's geometry helps to achieve more stable training dynamics.
  </figcaption>
</figure>





<p><strong>Optimal Transport Coupling</strong><br>For a generative transformation between two probability distributions, $q_0(x_0)$ and $q_1(x_1)$, the construction of the paths depends on the choice of the joint distribution $q(x_1, x_0)$ between the starting points $x_0$ and target points $x_1$. Mathematically, this joint distribution is known as a probabilistic coupling.</p>
<p>In the simplest setting, one can assume that the selection of the source and target samples is mutually independent, which constitutes an independent coupling:<br>\begin{equation}<br>q(x_1, x_0) &#x3D; q_1(x_1)q_0(x_0)<br>\end{equation}<br>However, this strategy completely ignores the relative geometric positions of the data points. When there are significant differences in the geometric shapes of the source and target distributions, random pairing can produce a large number of ‚Äòdetouring‚Äô or ‚Äòcrossing‚Äô paths, which in turn introduce instability into the model‚Äôs training.</p>
<p>To construct more efficient paths, it is necessary to introduce a \textbf{correlated coupling} that can reflect the geometric relationship between the distributions, i.e., $q(x_1, x_0) \neq q_1(x_1)q_0(x_0)$. Optimal Transport (OT) theory provides a solid mathematical foundation for this. The goal of OT is to find a joint distribution $\pi(x_1, x_0)$ that, among all possible pairing plans, minimizes the total transportation cost between sample pairs $(x_0, x_1)$. For the standard case using the squared Euclidean distance as the cost function, this problem can be formulated as the following Monge-Kantorovich problem:<br>\begin{equation}<br>q(x_1, x_0) &#x3D; \pi(x_1, x_0) \in \underset{\pi \in \Pi(q_0, q_1)}{\arg\inf} \iint |x_1 - x_0|_2^2 , d\pi(x_1, x_0)<br>\end{equation}</p>
<p>where $\Pi(q_0, q_1)$ represents the set of all valid couplings whose marginals are $q_0$ and $q_1$.</p>
<p>The solution to the above optimization problem is the optimal transport coupling, and its minimized cost value is directly related to the Squared 2-Wasserstein distance, $W_2^2(q_0, q_1)$. The coupling $\pi$ obtained in this way is no longer random; instead, it precisely matches each starting point $x_0$ with a geometrically ‚Äòoptimal‚Äô endpoint $x_1$. This geometry-based intelligent pairing can significantly simplify the marginal paths that the model ultimately needs to learn. It avoids unnecessary path crossings, thereby acting as a form of regularization, reducing variance during training, and making the learning process more stable and efficient.</p>
<p><strong>Visualization of Coupling Strategies and Path Geometry</strong></p>
<p>The preceding text introduced two core coupling strategies: independent coupling, based on statistical independence, and optimal transport coupling, based on geometric optimization. The choice of coupling strategy fundamentally determines the geometry of the conditional paths, which in turn directly affects the model‚Äôs training stability and efficiency. To provide an intuitive illustration of this point, Fig.7 uses three sets of numerical simulations to compare the dynamic properties of paths under different transformation tasks.</p>
<figure id="fig-sde-vs-ode" style="text-align:center;">
  <img src="/pic/8.png" alt="SDE vs ODE" style="max-width:95%;">
  <figcaption style="text-align:justify; font-size:90%;">
    <b>Fig.7Ôºö</b> <strong>Schematic comparison of paths under three Flow Matching frameworks:</strong> <strong>(Left)</strong> The probabilistic paths of Flow Matching are highly overlapping;
<strong>(Middle)</strong>The randomly paired paths of Conditional Flow Matching intersect with each other; 
 <strong>(Right)</strong> The optimally paired paths of OT Conditional Flow Matching are completely ordered and non-intersecting, representing a more stable learning process.
  </figcaption>
</figure>

<p>As shown in Fig.7, in the FM framework on the left, the paths are probabilistic. A particle starting from one mode of $P_0$ can end up in a superposition of any of the modes in $P_1$, which leads to significant path crossing and overlap, increasing the learning difficulty. The Conditional Flow Matching (CFM) with independent coupling in the middle defines paths by randomly pairing start and end points $(x_0, x_1)$. Although more direct than FM, the problem of path crossing between modes still exists, potentially leading to high training variance. In contrast, the OT Conditional Flow Matching (OT-CFM) on the right employs the principle of Optimal Transport for intelligent pairing, matching each starting point $x_0$ with an optimal endpoint $x_1$. This results in highly ordered paths and completely eliminates inter-modal crossing. Each mode flows independently to its corresponding target, thereby effectively reducing training variance and simplifying the learning process.</p>
<h1 class="no-number" >Conclusion</h1>

<p>This blog‚Äôs discourse begins with a deep insight into the randomness of the physical world, starting from the physical intuition of <strong>Brownian motion</strong> and introducing the core mathematical language to describe this process‚Äî<strong>Stochastic Differential Equations (SDEs) and It√¥‚Äôs Lemma</strong>. This solid theoretical foundation directly gave rise to the first major generative model paradigm: stochastic diffusion models. Under this paradigm, models like <strong>NCSN</strong> and <strong>DDPM</strong> both utilize SDEs to precisely simulate the stochastic process of data being gradually corrupted by noise and then restored by a learned reverse SDE. However, deep exploration of SDEs revealed their intrinsic connection to the deterministic world, namely the profound <strong>SDE-ODE duality</strong>. This theory points out that any SDE has an equivalent deterministic ODE evolution path, a breakthrough insight that made it possible to design deterministic samplers for stochastically trained models and directly gave rise to efficient acceleration algorithms like <strong>DDIM</strong>.</p>
<p>Building on this, the blog‚Äôs perspective turns to another, completely different technical route: <strong>deterministic generative models</strong>. Unlike the former, which may only use an ODE during reverse sampling, this class of models, such as <strong>Continuous Normalizing Flows (CNF)</strong>, is governed by deterministic ODEs in both the forward and reverse processes. To efficiently train these models, the article introduces the advanced framework of <strong>Flow Matching</strong>. The article further explores the core challenge in Flow Matching training: directly learning the ‚Äúmarginal vector field,‚Äù denoted as $u_t(x)$, is very difficult because its statistical properties at different times (such as high variance in the early stages) can lead to unstable training. Therefore, the model instead learns the more tractable ‚Äúconditional vector field,‚Äù denoted as $u_t(x|z)$. To fundamentally solve the conditional field variance problem caused by random pairing, the blog finally introduces <strong>Optimal Transport (OT)</strong> theory. By using OT to intelligently match start and end points, it is possible to construct geometrically ordered and non-crossing paths, which greatly stabilizes the training process and enhances the performance of models like <strong>OT-CFM</strong>.</p>
<div style="text-align:center;">
  <span style="font-size:22pt; font-weight:bold;">
    Appendix
  </span>
</div>


<p><span style="font-size:18pt; font-weight:bold;">A.  The Wiener Process &#x2F; Brownian Motion</span></p>
<p>A real-valued stochastic process ${W_t}_{t \ge 0}$ is called a Wiener process (or standard Brownian motion) if it satisfies the following conditions:</p>
<ol>
<li><strong>Initial Value:</strong> $W_0 &#x3D; 0$ (almost surely).</li>
<li><strong>Independent Increments:</strong> For any $0 \le s &lt; t$, the increment $W_t - W_s$ is independent of the history of the process before time $s$, $\sigma({W_r}_{0 \le r \le s})$.</li>
<li><strong>Gaussian Increments:</strong> For any $0 \le s &lt; t$, the increment $W_t - W_s$ follows a normal distribution with a mean of zero and a variance of $t-s$, i.e.:<br>$$<br>W_t - W_s \sim \mathcal{N}(0, t-s)<br>$$</li>
<li><strong>Continuous Paths:</strong> The sample paths $t \mapsto W_t$ are continuous almost everywhere.</li>
</ol>
<p>From these properties, a key characteristic of the Wiener process can be derived: its sample paths, while continuous, are nowhere differentiable and have a non-zero quadratic variation. Specifically, $[W, W]_t &#x3D; t$. On an infinitesimal level, this corresponds to the following heuristic relationship:<br>\begin{equation}<br>(\mathrm{d}W_t)^2 &#x3D; \mathrm{d}t<br>\label{eq:quadratic_variation_en}<br>\end{equation}<br>This relationship is the fundamental reason why stochastic calculus differs from classical calculus. It shows that although $dW_t$ is itself an infinitesimal quantity (on the order of $O(\sqrt{dt})$), its square is of the same order as $dt$ and thus cannot be ignored in Taylor expansions.</p>
<p><span style="font-size:18pt; font-weight:bold;">B.	It√¥‚Äôs Lemma and the It√¥ Integral</span></p>
<p>Because the paths of a Wiener process do not have bounded variation, the classical Riemann-Stieltjes integral is not applicable. Kiyosi It√¥ developed a new calculus theory to handle such processes. Its core result is \textbf{It√¥‚Äôs Lemma}, which provides the correct chain rule for stochastic processes.</p>
<p>Consider a twice continuously differentiable function $f(t, x)$, and let the stochastic process $X_t$ follow the  $\mathrm{d}X_t &#x3D; \mu_t \mathrm{d}t + \sigma_t \mathrm{d}W_t$. By performing a Taylor expansion and applying the rule from Eq.~\ref{eq:quadratic_variation_en}, the general form of It√¥‚Äôs Lemma can be obtained. For simplicity, we consider a function that depends only on the Wiener process, $f(W_t)$. Its infinitesimal change, $\mathrm{d}f(W_t)$, is:<br>$$<br>\mathrm{d}f(W_t) &#x3D; f(W_{t+\mathrm{d}t}) - f(W_t) \approx f‚Äô(W_t)\mathrm{d}W_t + \frac{1}{2}f‚Äô‚Äô(W_t)(\mathrm{d}W_t)^2<br>$$<br>Substituting $(\mathrm{d}W_t)^2 &#x3D; \mathrm{d}t$, we obtain the basic form of It√¥‚Äôs Lemma:<br>\begin{equation}<br>\mathrm{d}f(W_t) &#x3D; f‚Äô(W_t)\mathrm{d}W_t + \frac{1}{2}f‚Äô‚Äô(W_t)\mathrm{d}t<br>\label{eq:ito_lemma}<br>\end{equation}<br>The additional second-derivative term in this formula, $\frac{1}{2}f‚Äô‚Äô(W_t)\mathrm{d}t$, is the core difference between the It√¥ integral and the classical integral.</p>
<p>We can use It√¥‚Äôs Lemma to compute a classic \textbf{It√¥ Integral}. Let $f(W_t) &#x3D; W_t^2$, then $f‚Äô(W_t) &#x3D; 2W_t$ and $f‚Äô‚Äô(W_t) &#x3D; 2$. According to the lemma in Eq.~\eqref{eq:ito_lemma}, we have:<br>\begin{equation}<br>    \int_0^T \mathrm{d}(W_s^2) &#x3D; \int_0^T 2W_s \mathrm{d}W_s + \int_0^T \mathrm{d}s<br>\end{equation}<br>\begin{align}<br>    W_T^2 - W_0^2 &amp;&#x3D; 2\int_0^T W_s \mathrm{d}W_s + T \<br>    \implies \int_0^T W_s  \mathrm{d}W_s &#x3D; \frac{1}{2}W_T^2 - \frac{1}{2}T \label{eq:ito_integral_derivation}<br>\end{align}</p>
<p><span style="font-size:18pt; font-weight:bold;">C.	Derivation of the Reverse SDE Formula</span></p>
<p>Given a Stochastic Differential Equation (SDE), its discretized form is as follows:<br>$$<br>x_{t+\Delta t} - x_t &#x3D; f(x_t, t) \Delta t + g(t) \sqrt{\Delta t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)<br>$$</p>
<p>We can convert this into a conditional probability model:<br>$$<br>x_{t+\Delta t} \mid x_t \sim \mathcal{N}(x_t + f(x_t, t) \Delta t, g^2(t) \Delta t)<br>$$</p>
<p>Next, we consider the derivation of the conditional probability $ p(x_t \mid x_{t+\Delta t}) $:</p>
<p><img src="/pic/9.png" alt="ËøôÊòØÂõæÁâáËØ¥Êòé"></p>
<p>The resulting Gaussian distribution for the condition $ (x_t \mid x_{t+\Delta t})$ has:</p>
<p>$$<br>\mu &#x3D; x_{t+\Delta t} - \left( f(x_{t+\Delta t}, t + \Delta t) - g^2(t + \Delta t) \nabla_{x_{t+\Delta t}} \log p(x_{t+\Delta t}) \right) \Delta t<br>$$</p>
<p>$$<br>\sigma^2 &#x3D; g^2(t + \Delta t) \Delta t<br>$$</p>
<p>Next, we obtain the corresponding SDE, which is expressed in its discrete form as:<br>$$<br>x_{t+\Delta t} - x_t &#x3D; \left( f(x_{t+\Delta t}, t + \Delta t) - g^2(t + \Delta t) \nabla_{x_{t+\Delta t}} \log p(x_{t+\Delta t}) \right) \Delta t + g(t + \Delta t) \sqrt{\Delta t} \epsilon<br>$$<br>In the limit, this corresponds to the continuous SDE:<br>$$<br>dx &#x3D; \left[f(x, t) - g(t)^2 \nabla_x \log p_t(x)\right] dt + g(t) d\bar{w}<br>$$<br>where $ \epsilon \sim \mathcal{N}(0, I)$ is a standard normal random variable, and $d\bar{w}$ is a standard Wiener process.</p>
<p><span style="font-size:18pt; font-weight:bold;">D.	The Principle of Optimal Estimation and Its Application in Generative Models</span></p>
<p>In the training of probabilistic generative models, we often face a challenge: the theoretically ideal learning targets (such as the true marginal score or marginal vector field) are computationally intractable. However, a fundamental principle from statistical estimation theory provides a solid theoretical foundation for constructing equivalent and tractable learning objectives.</p>
<p><strong>The Principle of Optimal Estimation</strong><br>Let $X$ and $Y$ be two random variables (or vectors). We wish to find a function $g(X)$ that takes $X$ as input to serve as the best possible estimate of $Y$. If we use the minimum Mean Squared Error (MSE) as the criterion, then the optimal function $g^*(X)$ is the conditional expectation of $Y$ given $X$:<br>\begin{equation}<br>    g^*(X) &#x3D; \underset{g}{\arg\min} , \mathbb{E} \left[ | Y - g(X) |^2 \right] &#x3D; \mathbb{E}[Y \mid X]<br>\end{equation}</p>
<p>This theorem reveals a profound conclusion: for a loss function designed to fit a random variable $Y$, its optimal solution is the conditional expectation of $Y$.</p>
<p><strong>Application to Denoising Score Matching</strong><br>In diffusion models, our ultimate goal is to learn a network $s_\theta(x_t, t)$ that approximates the intractable marginal score function, $\nabla_{x_t}\log p_t(x_t)$.</p>
<p>According to <strong>Principle of Optimal Estimation</strong>, we can construct an equivalent and tractable learning objective. We define:</p>
<ul>
<li>The observed variable $X$ is the noisy sample $x_t$.</li>
<li>The target random variable $Y$ is the tractable conditional score function, $\nabla_{x_t}\log p_t(x_t|x_0)$. It is considered random because for a given $x_t$, the original sample $x_0$ from which it could have come is not unique.<br>In this case, the Denoising Score Matching loss function is $\mathcal{L}_{\text{DSM}}(\theta) &#x3D; \mathbb{E}[|s_\theta(x_t, t) - \nabla_{x_t}\log p_t(x_t|x_0)|^2]$. According to the theorem, the optimal solution $s_\theta^*$ that minimizes this loss is:<br>$$<br>s_\theta^*(x_t, t) &#x3D; \mathbb{E}[Y | X&#x3D;x_t] &#x3D; \mathbb{E}_{x_0 \sim p_t(x_0|x_t)} \left[ \nabla_{x_t} \log p_t(x_t|x_0) \right]<br>$$</li>
</ul>
<p><strong>Application to Conditional Flow Matching</strong><br>In Flow Matching, we encounter a completely analogous structure. Our ultimate goal is to learn a network $u_\theta(x_t, t)$ to approximate the intractable marginal vector field $u_t(x_t)$.</p>
<p>We can similarly apply <strong>Principle of Optimal Estimation</strong> to construct a tractable learning objective. We define:</p>
<ul>
<li>The observed variable $X$ is a sample on the path, $x_t$.</li>
<li>The target random variable $Y$ is the tractable conditional vector field, $u_t(x_t|z)$. It is considered random because for a given $x_t$, the possible path endpoints $z&#x3D;(x_0, x_1)$ are not unique.</li>
</ul>
<p>In this case, the Conditional Flow Matching loss function is $\mathcal{L}_{\text{CFM}}(\theta) &#x3D; \mathbb{E}[|u_\theta(x_t, t) - u_t(x_t|z)|^2]$. According to the theorem, the optimal solution $u_\theta^*$ that minimizes this loss is:<br>$$<br>u_\theta^*(x_t, t) &#x3D; \mathbb{E}[Y | X&#x3D;x_t] &#x3D; \mathbb{E}_{z \sim p_t(z|x_t)} \left[ u_t(x_t|z) \right]<br>$$</p>
<p><span style="font-size:18pt; font-weight:bold;">E.	Proof of $\nabla_\theta \mathcal{L}_{\text{FM}}(\theta) &#x3D; \nabla_\theta \mathcal{L}_{\text{CFM}}(\theta)$</span></p>
<p>To prove that optimizing the computable conditional loss $\mathcal{L}_{\text{CFM}}(\theta)$ is equivalent to optimizing the theoretical marginal loss $\mathcal{L}_{\text{FM}}(\theta)$, we only need to show that their gradients with respect to the model parameters $\theta$ are identical, i.e., $\nabla_\theta \mathcal{L}_{\text{FM}}(\theta) &#x3D; \nabla_\theta \mathcal{L}_{\text{CFM}}(\theta)$.</p>
<p>First, let‚Äôs write out the definitions of the two loss functions:</p>
<p>\begin{align}<br>\mathcal{L}_{\text{FM}}(\theta) &amp;&#x3D;<br>\mathbb{E}_{t, x \sim p_t} \left[ \lVert u_\theta(x, t) - u_t(x) \rVert_2^2 \right] \\<br>\mathcal{L}_{\text{CFM}}(\theta) &amp;&#x3D;<br>\mathbb{E}_{t, z \sim p_{\text{data}}, x \sim p_t(\cdot|z)}<br>\left[ \lVert u_\theta(x, t) - u_t(x|z) \rVert_2^2 \right]<br>\end{align}</p>
<p>Taking the gradient of $\mathcal{L}_{\text{CFM}}(\theta)$ and $\mathcal{L}_{\text{FM}}(\theta)$ with respect to $\theta$, we get:</p>
<p>\begin{align}<br>\nabla_\theta \mathcal{L}_{\text{CFM}}(\theta) &amp;&#x3D; \mathbb{E}_{t, z, x} \left[ \nabla_\theta | u_\theta(x, t) - u_t(x|z) |^2 \right] \nonumber \\<br>&amp;&#x3D; \mathbb{E}_{t, z, x} \left[ 2 \left( u_\theta(x, t) - u_t(x|z) \right) \cdot \nabla_\theta u_\theta(x, t) \right] \nonumber \\<br>&amp;&#x3D; \underbrace{2\mathbb{E}_{t, z, x} \left[ \langle u_\theta, \nabla_\theta u_\theta \rangle \right]}_{A}- \underbrace{2\mathbb{E}_{t, z, x} \left[ \langle u_t(x|z), \nabla_\theta u_\theta \rangle \right]}_{B}<br>\label{eq:grad_cfm}<br>\end{align}</p>
<p>\begin{equation}<br>\nabla_\theta \mathcal{L}_{\text{FM}}(\theta) &#x3D; \underbrace{2\mathbb{E}_{t, x} \left[ \langle u_\theta, \nabla_\theta u_\theta \rangle \right]}_{C} - \underbrace{2\mathbb{E}_{t, x} \left[ \langle u_t(x), \nabla_\theta u_\theta \rangle \right]}_{D}<br>\label{eq:grad_fm}<br>\end{equation}</p>
<p>To prove that the gradients are equal, we only need to show that in Eq.~\eqref{eq:grad_cfm} and \eqref{eq:grad_fm}, the terms satisfy $A&#x3D;C$ and $B&#x3D;D$.</p>
<p><strong>Proof that A&#x3D;C</strong><br>First, for any function $H(x,t)$ that depends only on $(x,t)$ (for example, $H &#x3D; \langle u_\theta, \nabla_\theta u_\theta \rangle$), its expectation under the two different probability measures is equal:<br>\begin{align*}<br>\mathbb{E}_{z \sim p_{\text{data}}, x \sim p_t(\cdot|z)} [H(x,t)] &amp;&#x3D; \iint H(x,t) , p_t(x|z) p_{\text{data}}(z) , \mathrm{d}z \mathrm{d}x \\<br>&amp;&#x3D; \int H(x,t) \left( \int p_t(x|z) p_{\text{data}}(z) , \mathrm{d}z \right) \mathrm{d}x \\<br>&amp;&#x3D; \int H(x,t) , p_t(x) , \mathrm{d}x &#x3D; \mathbb{E}_{x \sim p_t} [H(x,t)]<br>\end{align*}</p>
<p><strong>Proof that B&#x3D;D</strong><br>Using the identity  $u_t(x) &#x3D; \mathbb{E}_{z \sim p_t(z|x)}[u_t(x|z)]$Ôºö</p>
<p>\begin{align*}<br>\mathbb{E}_{x \sim p_t} [\langle u_t(x), \nabla_\theta u_\theta \rangle] &amp;&#x3D; \int \langle u_t(x), \nabla_\theta u_\theta \rangle p_t(x) , \mathrm{d}x  \\<br>&amp;&#x3D; \int \left\langle \mathbb{E}_{z \sim p_t(z|x)}[u_t(x|z)], \nabla_\theta u_\theta \right\rangle p_t(x) \ \mathrm{d}x \\<br>&amp;&#x3D; \int \left\langle \int u_t(x|z) p_t(z|x) , \mathrm{d}z, \nabla_\theta u_\theta \right\rangle p_t(x)  \mathrm{d}x \\<br>&amp;&#x3D; \iint \langle u_t(x|z), \nabla_\theta u_\theta \rangle p_t(z|x) p_t(x)  \mathrm{d}x \mathrm{d}z \\<br>&amp;&#x3D; \iint \langle u_t(x|z), \nabla_\theta u_\theta \rangle p_t(x|z) p_{\text{data}}(z)  \mathrm{d}x \mathrm{d}z \quad ( p_t(z|x)p_t(x) &#x3D; p_t(x|z)p_{\text{data}}(z)) \\<br>&amp;&#x3D; \mathbb{E}_{z \sim p_{\text{data}}, x \sim p_t(\cdot|z)} [\langle u_t(x|z), \nabla_\theta u_\theta \rangle]<br>\end{align*}</p>
<p>Since all corresponding terms in the gradient expressions for the two loss functions are equal, we conclude that:<br>$$<br>\nabla_\theta \mathcal{L}_{\text{FM}}(\theta) &#x3D; \nabla_\theta \mathcal{L}_{\text{CFM}}(\theta)<br>$$<br>Therefore, optimizing the computable $\mathcal{L}_{\text{CFM}}$ via gradient descent is mathematically equivalent to optimizing the theoretical $\mathcal{L}_{\text{FM}}$.</p>
<p><span style="font-size:18pt; font-weight:bold;">F.	The Conditional Vector Field</span></p>
<p>For the Gaussian probability path $p_t(x_t | x_1) &#x3D; \mathcal{N}(x_t; \mu_t(x_1), \sigma_t(x_1)^2 \mathbf{I})$, the corresponding flow map $\psi_t(x)$ has a unique corresponding vector field $u_t(x|x_1)$:<br>$$<br>u_t(x|x_1) &#x3D; \frac{\dot{\sigma}_t(x_1)}{\sigma_t(x_1)} \left(x - \mu_t(x_1)\right) + \dot{\mu}_t(x_1)<br>$$</p>
<p><strong>Proof</strong>: Since $\psi_t$ is invertible, let $x &#x3D; \psi_t^{-1}(y)$. Then we can write:<br>$$<br>\psi_t^{-1}(y) &#x3D; \frac{y - \mu_t(x_1)}{\sigma_t(x_1)}<br>$$</p>
<p>Simultaneously, differentiating $\psi_t$ yields:<br>$$<br>\psi_t‚Äô(x) &#x3D; \dot{\sigma}_t(x_1) x + \dot{\mu}_t(x_1)<br>$$</p>
<p>According to the ODE, we derive:<br>\begin{align*}<br>u_t(x|x_1) &amp;&#x3D; \dot{\psi}_t(x) &#x3D; \dot{\psi}_t\left(\psi_t^{-1}(y)\right) &#x3D; \psi_t‚Äô\left(\psi_t^{-1}(y)\right) \cdot \dot{y}(x_1) \\<br>&amp;&#x3D; \dot{\sigma}_t(x_1) \cdot \frac{y - \mu_t(x_1)}{\sigma_t(x_1)} + \dot{\mu}_t(x_1) \\<br>&amp;&#x3D; \frac{\dot{\sigma}_t(x_1)}{\sigma_t(x_1)} \left(x - \mu_t(x_1)\right) + \dot{\mu}_t(x_1)<br>\end{align*}</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yuxuan Qiu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">1</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yuxuan Qiu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
